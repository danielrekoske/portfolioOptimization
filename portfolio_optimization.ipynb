{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Optimization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.spatial.distance import squareform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class HRP:\n",
    "    def __init__(self, returns, clustering_method='single', risk_measure='variance'):\n",
    "        self.returns = returns\n",
    "        self.clustering_method = clustering_method\n",
    "        self.risk_measure = risk_measure\n",
    "        self.weights = None\n",
    "\n",
    "    def _get_cluster_var(self, cov, cluster):\n",
    "        \"\"\"\n",
    "        Compute cluster variance\n",
    "        \"\"\"\n",
    "        cov_slice = cov.loc[cluster, cluster]\n",
    "        return cov_slice.values.sum()\n",
    "\n",
    "    def _get_quasi_diag(self, link):\n",
    "        # Sort clustered items by distance\n",
    "        num_items = link.shape[0] + 1\n",
    "        sort_ix = pd.Series([link[-1, 0], link[-1, 1]], dtype=np.float64)\n",
    "        sort_ix.index = [0, 1]\n",
    "        while sort_ix.max() >= num_items:\n",
    "            sort_ix.index = range(sort_ix.shape[0])\n",
    "            df0 = sort_ix[sort_ix >= num_items]\n",
    "            i = df0.index\n",
    "            j = df0.values - num_items\n",
    "            sort_ix[i] = link[j.astype(int), 0]\n",
    "            df0 = pd.Series(link[j.astype(int), 1], index=i + 1, dtype=np.float64)\n",
    "            sort_ix = pd.concat([sort_ix, df0])\n",
    "            sort_ix = sort_ix.sort_index()\n",
    "            sort_ix.index = range(sort_ix.shape[0])\n",
    "        return sort_ix.astype(int).values\n",
    "\n",
    "    def fit(self):\n",
    "        if self.risk_measure == 'variance':\n",
    "            risk_matrix = self.returns.cov()\n",
    "            # Ensure the covariance matrix is symmetric\n",
    "            risk_matrix = (risk_matrix + risk_matrix.T) / 2\n",
    "        elif self.risk_measure == 'mad':\n",
    "            risk_matrix = self.returns.mad().to_frame().dot(self.returns.mad().to_frame().T)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported risk measure\")\n",
    "\n",
    "        # Check if risk_matrix is positive semi-definite\n",
    "        eigenvalues = np.linalg.eigvals(risk_matrix)\n",
    "        if not np.all(eigenvalues >= -1e-8):  # allow for small numerical errors\n",
    "            raise ValueError(\"Risk matrix is not positive semi-definite\")\n",
    "\n",
    "        corr = self.returns.corr()\n",
    "        dist = np.sqrt(np.clip((1 - corr) / 2., 0, 1))  # Ensure distance is non-negative\n",
    "        link = linkage(squareform(dist), method=self.clustering_method)\n",
    "        sorted_index = self._get_quasi_diag(link)\n",
    "\n",
    "        sorted_columns = self.returns.columns[sorted_index]\n",
    "        risk_matrix = risk_matrix.loc[sorted_columns, sorted_columns]\n",
    "        \n",
    "        weights = pd.Series(1.0, index=sorted_columns, dtype=np.float64)\n",
    "        clusters = [sorted_columns]\n",
    "\n",
    "        while len(clusters) > 0:\n",
    "            clusters = [cluster[start:end] for cluster in clusters\n",
    "                        for start, end in ((0, len(cluster) // 2),\n",
    "                                           (len(cluster) // 2, len(cluster)))\n",
    "                        if len(cluster) > 1]\n",
    "            for i in range(0, len(clusters), 2):\n",
    "                if i + 1 >= len(clusters):\n",
    "                    break\n",
    "                cluster0 = clusters[i]\n",
    "                cluster1 = clusters[i + 1]\n",
    "                \n",
    "                cluster0_var = self._get_cluster_var(risk_matrix, cluster0)\n",
    "                cluster1_var = self._get_cluster_var(risk_matrix, cluster1)\n",
    "                alpha = cluster1_var / (cluster0_var + cluster1_var)\n",
    "                \n",
    "                weights.loc[cluster0] *= alpha\n",
    "                weights.loc[cluster1] *= 1 - alpha\n",
    "\n",
    "        self.weights = weights / weights.sum()\n",
    "        return self.weights\n",
    "\n",
    "    def plot_dendrogram(self):\n",
    "        corr = self.returns.corr()\n",
    "        dist = np.sqrt((1 - corr) / 2.)\n",
    "        link = linkage(squareform(dist), method=self.clustering_method)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        dendrogram(link, labels=self.returns.columns)\n",
    "        plt.title('Hierarchical Clustering Dendrogram')\n",
    "        plt.xlabel('Asset')\n",
    "        plt.ylabel('Distance')\n",
    "        plt.show()\n",
    "\n",
    "    def get_weights(self):\n",
    "        if self.weights is None:\n",
    "            raise ValueError(\"You need to run the fit() method first\")\n",
    "        return self.weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "def fetch_stock_data(tickers, start_date, end_date):\n",
    "    data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n",
    "    return data\n",
    "\n",
    "def calculate_returns(prices):\n",
    "    return prices.pct_change().dropna()\n",
    "\n",
    "\n",
    "tickers = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'TSLA', 'NVDA', 'JPM', 'JNJ', 'V']\n",
    "\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2023-12-31'\n",
    "prices = fetch_stock_data(tickers, start_date, end_date)\n",
    "\n",
    "returns = calculate_returns(prices)\n",
    "hrp = HRP(returns, clustering_method='ward', risk_measure='variance')\n",
    "hrp.plot_dendrogram()\n",
    "hrp.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HERC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "class HERC:\n",
    "    def __init__(self, returns):\n",
    "        \"\"\"\n",
    "        Initialize the HERC class with returns data.\n",
    "        \n",
    "        Parameters:\n",
    "        returns (pd.DataFrame): Asset returns data.\n",
    "        \"\"\"\n",
    "        self.returns = returns\n",
    "        self.cov_matrix = returns.cov()\n",
    "        self.cor_matrix = returns.corr()\n",
    "    \n",
    "    def get_linkage_matrix(self):\n",
    "        \"\"\"\n",
    "        Get the linkage matrix using the correlation matrix.\n",
    "        \n",
    "        Returns:\n",
    "        Z (ndarray): Linkage matrix.\n",
    "        \"\"\"\n",
    "        corr_dist = np.sqrt((1 - self.cor_matrix) / 2)\n",
    "        dist_matrix = pdist(corr_dist)\n",
    "        Z = linkage(dist_matrix, 'ward')\n",
    "        return Z\n",
    "    \n",
    "    def get_clusters(self, Z, max_clusters=None):\n",
    "        \"\"\"\n",
    "        Get clusters from the linkage matrix.\n",
    "        \n",
    "        Parameters:\n",
    "        Z (ndarray): Linkage matrix.\n",
    "        max_clusters (int, optional): Maximum number of clusters. If None, a sensible value is chosen.\n",
    "        \n",
    "        Returns:\n",
    "        clusters (list): List of clusters.\n",
    "        \"\"\"\n",
    "        if max_clusters is None:\n",
    "            max_clusters = int(np.ceil(np.log(len(self.cor_matrix))))\n",
    "        clusters = fcluster(Z, max_clusters, criterion='maxclust')\n",
    "        return clusters\n",
    "    \n",
    "    def calculate_cluster_var(self, cluster):\n",
    "        \"\"\"\n",
    "        Calculate the variance of a cluster.\n",
    "        \n",
    "        Parameters:\n",
    "        cluster (list): List of asset indices in the cluster.\n",
    "        \n",
    "        Returns:\n",
    "        float: Cluster variance.\n",
    "        \"\"\"\n",
    "        cluster_cov = self.cov_matrix.iloc[cluster, cluster]\n",
    "        cluster_weights = np.ones(len(cluster)) / len(cluster)\n",
    "        cluster_var = cluster_weights.T @ cluster_cov @ cluster_weights\n",
    "        return cluster_var\n",
    "    \n",
    "    def get_cluster_var_contrib(self, weights, clusters):\n",
    "        \"\"\"\n",
    "        Get the variance contribution of each cluster.\n",
    "        \n",
    "        Parameters:\n",
    "        weights (ndarray): Portfolio weights.\n",
    "        clusters (list): List of clusters.\n",
    "        \n",
    "        Returns:\n",
    "        cluster_var_contrib (ndarray): Cluster variance contributions.\n",
    "        \"\"\"\n",
    "        cluster_var_contrib = np.zeros(np.max(clusters))\n",
    "        for i in range(1, np.max(clusters) + 1):\n",
    "            cluster_indices = np.where(clusters == i)[0]\n",
    "            cluster_weights = weights[cluster_indices]\n",
    "            cluster_cov = self.cov_matrix.iloc[cluster_indices, cluster_indices]\n",
    "            cluster_var = cluster_weights.T @ cluster_cov @ cluster_weights\n",
    "            cluster_var_contrib[i-1] = cluster_var\n",
    "        return cluster_var_contrib\n",
    "    \n",
    "    def objective(self, weights, clusters):\n",
    "        \"\"\"\n",
    "        Objective function to minimize.\n",
    "        \n",
    "        Parameters:\n",
    "        weights (ndarray): Portfolio weights.\n",
    "        clusters (list): List of clusters.\n",
    "        \n",
    "        Returns:\n",
    "        float: Objective value.\n",
    "        \"\"\"\n",
    "        cluster_var_contrib = self.get_cluster_var_contrib(weights, clusters)\n",
    "        total_var = weights.T @ self.cov_matrix.values @ weights\n",
    "        equal_contrib = np.ones(len(cluster_var_contrib)) / len(cluster_var_contrib)\n",
    "        return np.sum((cluster_var_contrib / total_var - equal_contrib) ** 2)\n",
    "    \n",
    "    def get_weights(self):\n",
    "        \"\"\"\n",
    "        Get the portfolio weights using the HERC method.\n",
    "        \n",
    "        Returns:\n",
    "        weights (pd.Series): Portfolio weights.\n",
    "        \"\"\"\n",
    "        Z = self.get_linkage_matrix()\n",
    "        clusters = self.get_clusters(Z)\n",
    "        \n",
    "        bounds = [(0, 1) for _ in range(len(self.returns.columns))]\n",
    "        constraints = [{'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1}]\n",
    "        initial_weights = np.ones(len(self.returns.columns)) / len(self.returns.columns)\n",
    "        \n",
    "        result = minimize(self.objective, initial_weights, args=(clusters,), bounds=bounds, constraints=constraints)\n",
    "        \n",
    "        if result.success:\n",
    "            return pd.Series(result.x, index=self.returns.columns)\n",
    "        else:\n",
    "            raise ValueError(\"Optimization failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "# Define the tickers and the period for which we want to download the data\n",
    "tickers = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'TSLA', 'NVDA', 'JPM', 'JNJ', 'V']\n",
    "period = '1y'\n",
    "\n",
    "# Download the historical data from Yahoo Finance\n",
    "data = yf.download(tickers, period=period)['Adj Close']\n",
    "\n",
    "# Calculate the daily returns\n",
    "returns = data.pct_change().dropna()\n",
    "\n",
    "# Initialize the HERC optimizer with the returns data\n",
    "herc = HERC(returns)\n",
    "\n",
    "# Get the optimized weights\n",
    "weights = herc.get_weights()\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black-Litterman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cvxopt import matrix, solvers\n",
    "\n",
    "class BlackLitterman:\n",
    "    def __init__(self, market_weights, cov_matrix, risk_free_rate, tau, P=None, Q=None, omega=None):\n",
    "        \"\"\"\n",
    "        Initializes the Black-Litterman model.\n",
    "        \n",
    "        :param market_weights: np.array, Market capitalization weights of the assets.\n",
    "        :param cov_matrix: np.array, Covariance matrix of the asset returns.\n",
    "        :param risk_free_rate: float, Risk-free rate.\n",
    "        :param tau: float, Scalar for the uncertainty of the prior.\n",
    "        :param P: np.array, Pick matrix representing the assets involved in the views.\n",
    "        :param Q: np.array, Expected returns vector corresponding to the views.\n",
    "        :param omega: np.array, Diagonal matrix representing the uncertainty of the views.\n",
    "        \"\"\"\n",
    "        self.market_weights = market_weights\n",
    "        self.cov_matrix = cov_matrix\n",
    "        self.risk_free_rate = risk_free_rate\n",
    "        self.tau = tau\n",
    "        self.P = P\n",
    "        self.Q = Q\n",
    "        self.omega = omega\n",
    "    \n",
    "    def implied_equilibrium_returns(self):\n",
    "        \"\"\"\n",
    "        Compute the implied equilibrium returns (pi).\n",
    "        \n",
    "        :return: np.array, Implied equilibrium returns.\n",
    "        \"\"\"\n",
    "        pi = self.tau * np.dot(self.cov_matrix, self.market_weights)\n",
    "        return pi\n",
    "    \n",
    "    def adjusted_returns(self):\n",
    "        \"\"\"\n",
    "        Compute the adjusted returns incorporating the investor's views.\n",
    "        \n",
    "        :return: np.array, Adjusted returns.\n",
    "        \"\"\"\n",
    "        pi = self.implied_equilibrium_returns()\n",
    "        \n",
    "        if self.P is not None and self.Q is not None and self.omega is not None:\n",
    "            M_inverse = np.linalg.inv(np.dot(self.P.T, np.dot(np.linalg.inv(self.omega), self.P)) + \n",
    "                                      np.linalg.inv(self.tau * self.cov_matrix))\n",
    "            adjusted_mean = M_inverse.dot(np.dot(np.linalg.inv(self.tau * self.cov_matrix), pi) + \n",
    "                                          np.dot(self.P.T, np.dot(np.linalg.inv(self.omega), self.Q)))\n",
    "        else:\n",
    "            adjusted_mean = pi\n",
    "            \n",
    "        return adjusted_mean\n",
    "    \n",
    "    def min_variance_allocation(self):\n",
    "        \"\"\"\n",
    "        Compute the minimum variance allocation.\n",
    "        \n",
    "        :return: np.array, Portfolio weights for the minimum variance portfolio.\n",
    "        \"\"\"\n",
    "        n = len(self.cov_matrix)\n",
    "        \n",
    "        # Convert to cvxopt matrices\n",
    "        P = matrix(self.cov_matrix)\n",
    "        q = matrix(np.zeros(n))\n",
    "        \n",
    "        # Constraints Gx <= h\n",
    "        G = matrix(np.diag([-1.0]*n))\n",
    "        h = matrix(np.zeros(n))\n",
    "        \n",
    "        # Constraints Ax = b\n",
    "        A = matrix(1.0, (1, n))\n",
    "        b = matrix(1.0)\n",
    "        \n",
    "        sol = solvers.qp(P, q, G, h, A, b)\n",
    "        return np.array(sol['x']).flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "tickers = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'TSLA', 'NVDA', 'JPM', 'JNJ', 'V']\n",
    "period = '1y'\n",
    "\n",
    "# Download the historical data from Yahoo Finance\n",
    "data = yf.download(tickers, period=period)['Adj Close']\n",
    "\n",
    "# Calculate the daily returns\n",
    "returns = data.pct_change().dropna()\n",
    "\n",
    "# Calculate the covariance matrix of returns\n",
    "cov_matrix = returns.cov().values\n",
    "\n",
    "# Example market weights (could be based on market capitalization)\n",
    "market_weights = np.array([0.15, 0.15, 0.15, 0.1, 0.1, 0.1, 0.1, 0.1, 0.05])\n",
    "\n",
    "# Arbitrary investor views\n",
    "P = np.array([[1, -1, 0, 0, 0, 0, 0, 0, 0], \n",
    "              [0, 0, 1, -1, 0, 0, 0, 0, 0]])\n",
    "Q = np.array([0.01, 0.02])\n",
    "omega = np.diag([0.0001, 0.0001])\n",
    "\n",
    "# Initialize the Black-Litterman model\n",
    "tau = 0.05\n",
    "bl = BlackLitterman(market_weights, cov_matrix, tau, P, Q, omega)\n",
    "\n",
    "# Calculate the implied and adjusted returns\n",
    "implied_returns = bl.implied_equilibrium_returns()\n",
    "adjusted_returns = bl.adjusted_returns()\n",
    "\n",
    "# Find the minimum variance portfolio\n",
    "min_variance_weights = bl.min_variance_allocation()\n",
    "\n",
    "print(\"Implied Equilibrium Returns:\", implied_returns)\n",
    "print(\"Adjusted Returns:\", adjusted_returns)\n",
    "print(\"Minimum Variance Portfolio Weights:\", min_variance_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markowitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cvxopt import matrix, solvers\n",
    "\n",
    "class Markowitz:\n",
    "    def __init__(self, returns):\n",
    "        \"\"\"\n",
    "        Initializes the Markowitz model with the returns data.\n",
    "        \n",
    "        :param returns: pd.DataFrame, Historical returns data for the assets.\n",
    "        \"\"\"\n",
    "        self.returns = returns\n",
    "        self.cov_matrix = returns.cov().values\n",
    "        self.n_assets = len(returns.columns)\n",
    "    \n",
    "    def min_variance_allocation(self):\n",
    "        \"\"\"\n",
    "        Compute the minimum variance allocation.\n",
    "        \n",
    "        :return: np.array, Portfolio weights for the minimum variance portfolio.\n",
    "        \"\"\"\n",
    "        n = self.n_assets\n",
    "        \n",
    "        # Convert to cvxopt matrices\n",
    "        P = matrix(self.cov_matrix)\n",
    "        q = matrix(np.zeros(n))\n",
    "        \n",
    "        # Constraints Gx <= h\n",
    "        G = matrix(np.diag([-1.0]*n))\n",
    "        h = matrix(np.zeros(n))\n",
    "        \n",
    "        # Constraints Ax = b\n",
    "        A = matrix(1.0, (1, n))\n",
    "        b = matrix(1.0)\n",
    "        \n",
    "        sol = solvers.qp(P, q, G, h, A, b)\n",
    "        return np.array(sol['x']).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "tickers = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'TSLA', 'NVDA', 'JPM', 'JNJ', 'V']\n",
    "period = '1y'\n",
    "\n",
    "# Download the historical data from Yahoo Finance\n",
    "data = yf.download(tickers, period=period)['Adj Close']\n",
    "\n",
    "# Calculate the daily returns\n",
    "returns = data.pct_change().dropna()\n",
    "\n",
    "# Initialize the Markowitz model with the returns data\n",
    "markowitz = Markowitz(returns)\n",
    "\n",
    "# Get the minimum variance portfolio weights\n",
    "min_variance_weights = markowitz.min_variance_allocation()\n",
    "\n",
    "print(\"Minimum Variance Portfolio Weights:\", min_variance_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copula-Based Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from copulas.multivariate import VineCopula\n",
    "from copulas.visualization import scatter_2d\n",
    "\n",
    "class CopulaOptimizer:\n",
    "    def __init__(self, returns, n_simulations=100):\n",
    "        self.returns = returns\n",
    "        self.n_simulations = n_simulations\n",
    "        self.n_assets = returns.shape[1]\n",
    "        self.copula = VineCopula('center')\n",
    "\n",
    "    def fit_copula(self):\n",
    "        self.copula.fit(self.returns)\n",
    "    \n",
    "    def simulate_returns(self):\n",
    "        simulated_data = self.copula.sample(self.n_simulations)\n",
    "        simulated_returns = pd.DataFrame(simulated_data, columns=self.returns.columns)\n",
    "        return simulated_returns\n",
    "    \n",
    "    def portfolio_return(self, weights, returns):\n",
    "        return np.dot(weights, returns.mean())\n",
    "    \n",
    "    def portfolio_volatility(self, weights, returns):\n",
    "        return np.sqrt(np.dot(weights.T, np.dot(returns.cov(), weights)))\n",
    "    \n",
    "    def negative_sharpe_ratio(self, weights, returns, risk_free_rate=0):\n",
    "        p_return = self.portfolio_return(weights, returns)\n",
    "        p_volatility = self.portfolio_volatility(weights, returns)\n",
    "        return -(p_return - risk_free_rate) / p_volatility\n",
    "    \n",
    "    def optimize_portfolio(self, risk_free_rate=0):\n",
    "        constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "        bounds = tuple((0, 1) for _ in range(self.n_assets))\n",
    "        initial_guess = self.n_assets * [1. / self.n_assets]\n",
    "        \n",
    "        simulated_returns = self.simulate_returns()\n",
    "        \n",
    "        result = minimize(\n",
    "            self.negative_sharpe_ratio,\n",
    "            initial_guess,\n",
    "            args=(simulated_returns, risk_free_rate),\n",
    "            method='SLSQP',\n",
    "            bounds=bounds,\n",
    "            constraints=constraints\n",
    "        )\n",
    "        \n",
    "        return result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "# Define the tickers and the period for which we want to download the data\n",
    "tickers = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'TSLA', 'NVDA', 'JPM', 'JNJ', 'V']\n",
    "period = '1y'\n",
    "\n",
    "# Download the historical data from Yahoo Finance\n",
    "data = yf.download(tickers, period=period)['Adj Close']\n",
    "\n",
    "# Calculate the daily returns\n",
    "returns = data.pct_change().dropna()\n",
    "\n",
    "optimizer = CopulaOptimizer(returns)\n",
    "optimizer.fit_copula()\n",
    "optimized_weights = optimizer.optimize_portfolio()\n",
    "print(\"Optimized Portfolio Weights:\", optimized_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.spatial.distance import pdist\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MinimumSpanningTree:\n",
    "    def __init__(self, returns: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Initialize with stock returns.\n",
    "        \n",
    "        Parameters:\n",
    "        returns (pd.DataFrame): DataFrame where each column represents a stock and each row represents a return for a time period.\n",
    "        \"\"\"\n",
    "        self.returns = returns\n",
    "        self.distance_matrix = None\n",
    "        self.mst = None\n",
    "\n",
    "    def calculate_distance_matrix(self):\n",
    "        \"\"\"\n",
    "        Calculate the distance matrix using Pearson correlation.\n",
    "        \"\"\"\n",
    "        correlation_matrix = self.returns.corr()\n",
    "        distance_matrix = np.sqrt(2 * (1 - correlation_matrix))\n",
    "        self.distance_matrix = pd.DataFrame(distance_matrix, index=correlation_matrix.index, columns=correlation_matrix.columns)\n",
    "\n",
    "    def compute_mst(self):\n",
    "        \"\"\"\n",
    "        Compute the Minimum Spanning Tree (MST) using Kruskal's algorithm.\n",
    "        \"\"\"\n",
    "        if self.distance_matrix is None:\n",
    "            self.calculate_distance_matrix()\n",
    "\n",
    "        # Create a graph from the distance matrix\n",
    "        dist_array = pdist(self.distance_matrix)\n",
    "        graph = nx.Graph()\n",
    "\n",
    "        stocks = self.distance_matrix.columns\n",
    "        for i in range(len(stocks)):\n",
    "            for j in range(i + 1, len(stocks)):\n",
    "                graph.add_edge(stocks[i], stocks[j], weight=squareform(dist_array)[i, j])\n",
    "\n",
    "        # Compute MST using Kruskal's algorithm\n",
    "        self.mst = nx.minimum_spanning_tree(graph)\n",
    "\n",
    "    def plot_mst(self):\n",
    "        \"\"\"\n",
    "        Plot the Minimum Spanning Tree.\n",
    "        \"\"\"\n",
    "        if self.mst is None:\n",
    "            self.compute_mst()\n",
    "\n",
    "        pos = nx.spring_layout(self.mst)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        nx.draw(self.mst, pos, with_labels=True, node_size=3000, node_color='skyblue', font_size=15, font_weight='bold')\n",
    "        edge_labels = nx.get_edge_attributes(self.mst, 'weight')\n",
    "        nx.draw_networkx_edge_labels(self.mst, pos, edge_labels=edge_labels, font_size=10)\n",
    "        plt.title('Minimum Spanning Tree of Stock Returns')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "# Define the tickers and the period for which we want to download the data\n",
    "tickers = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'TSLA', 'NVDA', 'JPM', 'JNJ', 'V']\n",
    "period = '1y'\n",
    "\n",
    "# Download the historical data from Yahoo Finance\n",
    "data = yf.download(tickers, period=period)['Adj Close']\n",
    "\n",
    "# Calculate the daily returns\n",
    "returns = data.pct_change().dropna()\n",
    "mst_calculator = MinimumSpanningTree(returns)\n",
    "mst_calculator.plot_mst()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
